{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from csv file, csv is extracted by running trained NS-VQA on CLEVR-min dataset\n",
    "DATA_PATH = r'C:/Users/pegah/Desktop/programs_and_params_with_traces.csv'\n",
    "data_raw = pd.read_csv(DATA_PATH)\n",
    "data = data_raw.loc[data_raw.a_gt == data_raw.a_pr]\n",
    "\n",
    "# modify data and get those needed\n",
    "bad = ['relate[behind]','relate[front]','relate[left]','relate[right]','same_color','same_material',\\\n",
    "       'same_shape','same_size', 'union', 'intersect']\n",
    "      \n",
    "bad_idx = []\n",
    "for i in range(len(data.p_trace)):\n",
    "    try:\n",
    "        for m in eval(data.p_trace[i]):\n",
    "            try:\n",
    "                a = m['token']\n",
    "                if a in bad:\n",
    "                    bad_idx.append(i)\n",
    "                    break\n",
    "            except:\n",
    "                bad_idx.append(i)\n",
    "                break\n",
    "    except:\n",
    "        bad_idx.append(i)\n",
    "        \n",
    "\n",
    "bad_idx.extend([149989,149990])  # somehow these wree left out!\n",
    "copy_bad_idx = [i for i in bad_idx if i not in [15758, 36228]]\n",
    "new_data = data.drop(copy_bad_idx)\n",
    "\n",
    "# filter those whose answer only depends on previous step\n",
    "bad_idx = []\n",
    "for i in new_data.index:\n",
    "    tok = [var['token'] for var in eval(new_data.p_trace[i]) if var['token'] != '<END>'][1:]\n",
    "    if 'scene' in tok:\n",
    "        bad_idx.append(i)\n",
    "new_data = new_data.drop(bad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "cols = ['id', 'position', 'color', 'material', 'shape', 'size']\n",
    "VQA_MODULES = ['count','equal_color','equal_integer','equal_material','equal_shape','equal_size','exist',\\\n",
    "'filter_color[blue]','filter_color[brown]','filter_color[cyan]','filter_color[gray]',\\\n",
    "'filter_color[green]','filter_color[purple]','filter_color[red]','filter_color[yellow]',\\\n",
    "'filter_material[rubber]','filter_material[metal]','filter_shape[cube]','filter_shape[cylinder]',\\\n",
    "'filter_shape[sphere]','filter_size[large]','filter_size[small]','greater_than','less_than',\\\n",
    "'query_color','query_material','query_shape','query_size','relate[behind]','relate[front]','relate[left]',\\\n",
    "'relate[right]','same_color','same_material','same_shape','same_size','unique']\n",
    "COMPARE_MODULES = ['equal_color','equal_integer','equal_material','equal_shape','equal_size','greater_than','less_than']\n",
    "FILTER_MODULES = ['filter_color[blue]','filter_color[brown]','filter_color[cyan]','filter_color[gray]',\\\n",
    "'filter_color[green]','filter_color[purple]','filter_color[red]','filter_color[yellow]',\\\n",
    "'filter_material[rubber]','filter_material[metal]','filter_shape[cube]','filter_shape[cylinder]',\\\n",
    "'filter_shape[sphere]','filter_size[large]','filter_size[small]']\n",
    "QUERY_MODULES = ['query_color','query_material','query_shape','query_size']\n",
    "RELATE_MODULES = ['relate[behind]','relate[front]','relate[left]','relate[right]']\n",
    "SAME_MODULES = ['same_color','same_material','same_shape','same_size']\n",
    "NPI_PROGRAMS = ['COUNT','COMPARE','MOVE_PTR','DELETE_ROW','QUERY','UNIQUE','EXIST','FILTER']\n",
    "NPI_PROG_ID = {NPI_PROGRAMS[i]: i for i in range(len(NPI_PROGRAMS))}\n",
    "ARG = {'COMPARE': {k:['EQ','GT', 'LT', 'NEQ'].index(k) for k in ['EQ','GT', 'LT', 'NEQ']},\n",
    "        'FILTER': {1: {k.upper():cols[2:].index(k) for k in cols[2:]},\n",
    "                   2: {k:['BLUE', 'BROWN', 'CYAN', 'GRAY', 'GREEN', 'PURPLE', 'RED', 'YELLOW', \\\n",
    "                         'RUBBER', 'METAL', 'CUBE', 'CYLINDER', 'SPHERE', 'LARGE', 'SMALL'].index(k) for\\\n",
    "                       k in ['BLUE', 'BROWN', 'CYAN', 'GRAY', 'GREEN', 'PURPLE', 'RED', 'YELLOW', \\\n",
    "                         'RUBBER', 'METAL', 'CUBE', 'CYLINDER', 'SPHERE', 'LARGE', 'SMALL']}},\n",
    "        'QUERY': {k.upper():cols.index(k) for k in cols[1:]},\n",
    "        'RELATE': {k:['BEHIND', 'FRONT', 'LEFT', 'RIGHT'].index(k) for k in ['BEHIND', 'FRONT', 'LEFT', 'RIGHT']},\n",
    "        'SAME': {k.upper():cols[2:].index(k) for k in cols[2:]},\n",
    "        'MOVE_PTR': {1: {k.upper():v for (k,v) in zip(cols, range(len(cols)))}, 2: {k:['DOWN','RESET'].index(k) for k in ['DOWN','RESET']}}\n",
    "                  }\n",
    "ARG_R = {'COMPARE': {k:v for (v,k) in ARG['COMPARE'].items()},\\\n",
    "        'FILTER': {1: {k:v for (v,k) in ARG['FILTER'][1].items()},\\\n",
    "                   2: {k:v for (v,k) in ARG['FILTER'][2].items()}},\\\n",
    "        'QUERY': {k:v for (v,k) in ARG['QUERY'].items()},\\\n",
    "        'RELATE': {k:v for (v,k) in ARG['RELATE'].items()},\\\n",
    "        'SAME': {k:v for (v,k) in ARG['SAME'].items()},\\\n",
    "        'MOVE_PTR': {1: {k:v for (v,k) in ARG['MOVE_PTR'][1].items()}, 2: {k:v for (v,k) in ARG['MOVE_PTR'][2].items()}}}\n",
    "H_PROG = ['FILTER', 'RELATE', 'SAME', 'EXIST']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def map_module(module):\n",
    "    \"\"\" \n",
    "    Turn the output of VQA seq-to-seq parsing of the question (a string module) into NPI module. \n",
    "    return: (NPI_program, program_id) , [Arg]\n",
    "    \"\"\"\n",
    "    if module not in VQA_MODULES:\n",
    "        return 'error in map_module: unknown module'\n",
    "    if module in COMPARE_MODULES: \n",
    "        tmp = ('COMPARE', NPI_PROG_ID['COMPARE'])\n",
    "        arg1 = module.split('_')[0]\n",
    "        if arg1 == 'equal':\n",
    "            return tmp, [ARG['COMPARE']['EQ']]\n",
    "        elif arg1 == 'greater':\n",
    "            return tmp, [ARG['COMPARE']['GT']]\n",
    "        elif arg1 == 'less':\n",
    "            return tmp, [ARG['COMPARE']['LT']]\n",
    "        else: \n",
    "            return 'error in map_modlue: unknown argument'\n",
    "    elif module in FILTER_MODULES:\n",
    "        [arg1 ,arg2] = module.split('_')[1].split('[') \n",
    "        arg2 = arg2[:-1]\n",
    "        return ('FILTER', NPI_PROG_ID['FILTER']) , [ARG['FILTER'][1][arg1.upper()], ARG['FILTER'][2][arg2.upper()]]    \n",
    "    elif module in QUERY_MODULES:\n",
    "        arg1 = module.split('_')[1]\n",
    "        return ('QUERY', NPI_PROG_ID['QUERY']) , [ARG['QUERY'][arg1.upper()]]\n",
    "    elif module in RELATE_MODULES:\n",
    "        arg1 = module.split('[')[1][:-1]\n",
    "        return ('RELATE', NPI_PROG_ID['RELATE']), [ARG['RELATE'][arg1.upper()]]\n",
    "    elif module in SAME_MODULES:\n",
    "        arg1 = module.split('_')[1]\n",
    "        return ('SAME', NPI_PROG_ID['SAME']), [ARG['SAME'][arg1.upper()]]\n",
    "    else: \n",
    "        return (module.upper(), NPI_PROG_ID[module.upper()]) , []\n",
    "\n",
    "# can improve by adding def of all lowr level functions used inside a class \"scene\", add \"self\" and call those here\n",
    "def exec_prog(prog, args, scene, term):\n",
    "    res = []\n",
    "    if prog =='FILTER':\n",
    "        if len(args) != 2:\n",
    "            return ('error in executing FILTER: wrong number of args ({} instead of 2)'.format(len(args)))\n",
    "        if len(scene) == 0:\n",
    "            return ('error in executing FILTER: empty scene')\n",
    "        arg1 = ARG_R[prog][1][args[0]]  # color,...\n",
    "        arg2 = ARG_R[prog][2][args[1]]  # blue,...\n",
    "#         # make new scene\n",
    "#         mod = 'NEW_SCENE'\n",
    "        new_s = []\n",
    "#         res.append(((mod, NPI_PROG_ID[mod]),[],False))\n",
    "        step = 0\n",
    "        # loop over all objects (number of dicts in scene)\n",
    "        for row in scene:\n",
    "            step += 1\n",
    "            # move col and row pointers one down\n",
    "            mod =  'MOVE_PTR'\n",
    "            res.append(((mod, NPI_PROG_ID[mod]),[ARG[mod][1][arg1], ARG[mod][2]['DOWN']],False))\n",
    "            res.append(((mod, NPI_PROG_ID[mod]),[ARG[mod][1]['ID'], ARG[mod][2]['DOWN']],False))\n",
    "            # compare\n",
    "            mod = 'COMPARE'\n",
    "            if row[arg1.lower()] != arg2.lower():\n",
    "                res.append(((mod, NPI_PROG_ID[mod]),[ARG[mod]['EQ']],False))\n",
    "                # add row to new_scene = new_s\n",
    "                new_s.append(row)\n",
    "                # check for terminattion\n",
    "                mod = 'DELETE_ROW'                    \n",
    "                res.append(((mod, NPI_PROG_ID[mod]),[],False))\n",
    "            else:\n",
    "                res.append(((mod, NPI_PROG_ID[mod]),[ARG[mod]['EQ']], False))\n",
    "        mod =  'MOVE_PTR'\n",
    "        res.append(((mod, NPI_PROG_ID[mod]),[ARG[mod][1][arg1], ARG[mod][2]['RESET']],False))\n",
    "        res.append(((mod, NPI_PROG_ID[mod]),[ARG[mod][1]['ID'], ARG[mod][2]['RESET']],term))\n",
    "#         mod = 'EXIT'\n",
    "#         res.append(((mod, NPI_PROG_ID[mod]),[],term))\n",
    "        return res, new_s\n",
    "                           \n",
    "    elif prog == 'EXIST':\n",
    "        # count number of objects in a scene\n",
    "        obj_num = len(scene)\n",
    "        mod =  'COUNT'\n",
    "        res.append(((mod, NPI_PROG_ID[mod]),[],False))\n",
    "        # compare if number is greater than zero\n",
    "        mod = 'COMPARE'\n",
    "        res.append(((mod, NPI_PROG_ID[mod]),[ARG[mod]['GT']],term)) \n",
    "#         mod = 'EXIT'\n",
    "#         res.append(((mod, NPI_PROG_ID[mod]),[],term))\n",
    "        \n",
    "        if obj_num > 0: \n",
    "            return res, 'yes'\n",
    "        else:\n",
    "            return res, 'no'\n",
    "            \n",
    "#     if prog =='RELATE'\n",
    "#     if prog =='SAME'\n",
    "\n",
    "\n",
    "def build_trace(module, s_prev, term):  \n",
    "    \"\"\" \n",
    "        return [((,),[],False),..., ((,),[],True/False)] if higher level program, else just [((,),[],True/False)] \n",
    "    \"\"\"\n",
    "    tmp = map_module(module)  # (('FILTER', 8), [0, 1])\n",
    "    prog = tmp[0][0]\n",
    "    if prog in H_PROG: \n",
    "        result = [tmp + (False,)] \n",
    "        res, s_update = exec_prog(prog, tmp[1], s_prev, term)\n",
    "        result.extend(res)\n",
    "    else:\n",
    "        result = [tmp + (term,)]\n",
    "    return result\n",
    "\n",
    "def build_npi_data(data):\n",
    "    \"\"\" build training/testing data for inputs to npi (trace = execution trace)\"\"\"\n",
    "    trace = []  # [(imgid_q1,trace_list), (imgid_q2, trace_list), ...]\n",
    "    dbg = 0\n",
    "    for (a_gt,imgid, vqa_trc, qid, qtype) in zip(data.a_gt, data.image_id, data.p_trace, data.q_id, data.q_type):\n",
    "        terminate = False\n",
    "        dbg += 1\n",
    "        step = 0\n",
    "        scene_prev = []\n",
    "        trace_list = []  # for each row of p_trace(i.e. each question): [((,),[],False),..., ((,),[],True/False)]\n",
    "        for mdl in eval(vqa_trc):\n",
    "            step += 1\n",
    "            if step == len(eval(vqa_trc)):\n",
    "                terminate = True\n",
    "            module = mdl['token']\n",
    "            scene_now = mdl['ans']\n",
    "            if module in ['<END>', 'scene',]:\n",
    "                scene_prev = scene_now\n",
    "                continue\n",
    "            elif module in VQA_MODULES:\n",
    "                try:\n",
    "                    trace_list.extend(build_trace(module, scene_prev, terminate))\n",
    "                    continue\n",
    "                except:\n",
    "                    print('error: undefined vqa module {} in step {}'.format(module, dbg))\n",
    "                    break\n",
    "            else: \n",
    "                print('error: unknown module in vqa trace')\n",
    "                break\n",
    "        trace.append((a_gt, imgid, qid, qtype, trace_list))\n",
    "    return trace\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train and test data (new.data.shape = (10044, 12))\n",
    "train_data = new_data[:8000]\n",
    "test_data = new_data[8000:]\n",
    "# save train and test data\n",
    "train_result = build_npi_data(train_data)\n",
    "test_result = build_npi_data(test_data)\n",
    "name = 'train'\n",
    "with open(r'C:\\Users\\pegah\\Desktop\\vqa-npi\\tasks\\vqa\\data\\{}.pickle'.format(name), 'wb') as f:\n",
    "    pickle.dump(train_result, f)\n",
    "name = 'test'\n",
    "with open(r'C:\\Users\\pegah\\Desktop\\vqa-npi\\tasks\\vqa\\data\\{}.pickle'.format(name), 'wb') as f:\n",
    "    pickle.dump(test_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data by the question type and question trace length \n",
    "# q by type\n",
    "t_type = {}\n",
    "for i in train_result:\n",
    "    if i[3] not in t_type:\n",
    "        t_type[i[3]]= [i]\n",
    "    else:\n",
    "        t_type[i[3]].append(i)\n",
    "# q by len\n",
    "t_len_less = []\n",
    "t_len_more = []\n",
    "for i in train_result:\n",
    "    if len(i[4]) <= 20 :\n",
    "        t_len_less.append(i)\n",
    "    else:\n",
    "        t_len_more.append(i)\n",
    "        \n",
    "train_query = t_type['query']\n",
    "train_count = t_type['count']\n",
    "train_exist = t_type['exist']\n",
    "train_less20 = t_len_less\n",
    "train_more20 = t_len_more\n",
    "\n",
    "# save\n",
    "name = 'train_query'\n",
    "with open(r'C:\\Users\\pegah\\Desktop\\vqa-npi\\tasks\\vqa\\data\\{}.pickle'.format(name), 'wb') as f:\n",
    "    pickle.dump(train_query, f)\n",
    "name = 'train_count'\n",
    "with open(r'C:\\Users\\pegah\\Desktop\\vqa-npi\\tasks\\vqa\\data\\{}.pickle'.format(name), 'wb') as f:\n",
    "    pickle.dump(train_count, f)\n",
    "name = 'train_exist'\n",
    "with open(r'C:\\Users\\pegah\\Desktop\\vqa-npi\\tasks\\vqa\\data\\{}.pickle'.format(name), 'wb') as f:\n",
    "    pickle.dump(train_exist, f)\n",
    "name = 'train_less20'\n",
    "with open(r'C:\\Users\\pegah\\Desktop\\vqa-npi\\tasks\\vqa\\data\\{}.pickle'.format(name), 'wb') as f:\n",
    "    pickle.dump(train_less20, f)\n",
    "name = 'train_more20'\n",
    "with open(r'C:\\Users\\pegah\\Desktop\\vqa-npi\\tasks\\vqa\\data\\{}.pickle'.format(name), 'wb') as f:\n",
    "    pickle.dump(train_more20, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
